{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b57703aa",
   "metadata": {},
   "source": [
    "# Summarize Dialogue without Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7dfff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /home/azadeh/.local/lib/python3.8/site-packages (23.2.1)\n",
      "\u001b[33mDEPRECATION: distro-info 0.23ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.36ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: distro-info 0.23ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.36ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: distro-info 0.23ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.36ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.11.0  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82078058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37edb04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/azadeh/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c401d6706a4ea5a0d612457ef432cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# huggingface dataset\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3adeb546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "#Person1#: OK, that's a cut! Let's start from the beginning, everyone.\n",
      "#Person2#: What was the problem that time?\n",
      "#Person1#: The feeling was all wrong, Mike. She is telling you that she doesn't want to see you any more, but I want to get more anger from you. You're acting hurt and sad, but that's not how your character would act in this situation.\n",
      "#Person2#: But Jason and Laura have been together for three years. Don't you think his reaction would be one of both anger and sadness?\n",
      "#Person1#: At this point, no. I think he would react the way most guys would, and then later on, we would see his real feelings.\n",
      "#Person2#: I'm not so sure about that.\n",
      "#Person1#: Let's try it my way, and you can see how you feel when you're saying your lines. After that, if it still doesn't feel right, we can try something else.\n",
      "\n",
      "Summary:\n",
      "#Person1# and Mike have a disagreement on how to act out a scene. #Person1# proposes that Mike can try to act in #Person1#'s way.\n",
      "    \n",
      "-------------------------------------\n",
      "Dialogue:\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "Summary:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "    \n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "indeces = [100,200]\n",
    "for idx in indeces:\n",
    "    d = dataset[\"test\"][idx]['dialogue']\n",
    "    s = dataset[\"test\"][idx]['summary']\n",
    "    \n",
    "    text = f\"\"\"Dialogue:\\n{d}\\n\\nSummary:\\n{s}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(text)\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1870f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f501f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODED SENTENCE:\n",
      "tensor([  101,  1431,     3,     9,  1081,    12,   794,   749,  1167,    17,\n",
      "           18, 20165,    49,    53,     1])\n",
      "\n",
      "DECODED SENTENCE:\n",
      "We write a code to test Prompt-engineering\n"
     ]
    }
   ],
   "source": [
    "# Test the quality of the tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "sentence = \"We write a code to test Prompt-engineering\"\n",
    "\n",
    "sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "sentence_decoded = tokenizer.decode(\n",
    "        sentence_encoded[\"input_ids\"][0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "print('ENCODED SENTENCE:')\n",
    "print(sentence_encoded[\"input_ids\"][0])\n",
    "print('\\nDECODED SENTENCE:')\n",
    "print(sentence_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a06fdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialogue:\n",
      "#Person1#: OK, that's a cut! Let's start from the beginning, everyone.\n",
      "#Person2#: What was the problem that time?\n",
      "#Person1#: The feeling was all wrong, Mike. She is telling you that she doesn't want to see you any more, but I want to get more anger from you. You're acting hurt and sad, but that's not how your character would act in this situation.\n",
      "#Person2#: But Jason and Laura have been together for three years. Don't you think his reaction would be one of both anger and sadness?\n",
      "#Person1#: At this point, no. I think he would react the way most guys would, and then later on, we would see his real feelings.\n",
      "#Person2#: I'm not so sure about that.\n",
      "#Person1#: Let's try it my way, and you can see how you feel when you're saying your lines. After that, if it still doesn't feel right, we can try something else.\n",
      "\n",
      "Ground-Truth:\n",
      "#Person1# and Mike have a disagreement on how to act out a scene. #Person1# proposes that Mike can try to act in #Person1#'s way.\n",
      "\n",
      "Model Generated Output:\n",
      "#Person1#: I'm sorry, but I'm not sure what Jason and Laura are doing.\n",
      "\n",
      "Dialogue:\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "Ground-Truth:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "\n",
      "Model Generated Output:\n",
      "#Person1#: I'm thinking of upgrading my computer.\n"
     ]
    }
   ],
   "source": [
    "example_indices = [100,200]\n",
    "\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['dialogue']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "    \n",
    "    inputs = tokenizer(dialogue, return_tensors='pt')\n",
    "    output = tokenizer.decode(model.generate(inputs[\"input_ids\"],\n",
    "                  max_new_tokens = 150,\n",
    "                  )[0],\n",
    "                    skip_special_tokens=True\n",
    "                )\n",
    "    print()\n",
    "    print(\"Dialogue:\")\n",
    "    print(dialogue)\n",
    "    \n",
    "    print()\n",
    "    print(\"Ground-Truth:\")\n",
    "    print(summary)\n",
    "    print()\n",
    "    \n",
    "    print(\"Model Generated Output:\")\n",
    "    print(output)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f0439",
   "metadata": {},
   "source": [
    "# Zero-shot with instruction prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76e08781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialogue:\n",
      "#Person1#: OK, that's a cut! Let's start from the beginning, everyone.\n",
      "#Person2#: What was the problem that time?\n",
      "#Person1#: The feeling was all wrong, Mike. She is telling you that she doesn't want to see you any more, but I want to get more anger from you. You're acting hurt and sad, but that's not how your character would act in this situation.\n",
      "#Person2#: But Jason and Laura have been together for three years. Don't you think his reaction would be one of both anger and sadness?\n",
      "#Person1#: At this point, no. I think he would react the way most guys would, and then later on, we would see his real feelings.\n",
      "#Person2#: I'm not so sure about that.\n",
      "#Person1#: Let's try it my way, and you can see how you feel when you're saying your lines. After that, if it still doesn't feel right, we can try something else.\n",
      "\n",
      "Ground-Truth:\n",
      "#Person1# and Mike have a disagreement on how to act out a scene. #Person1# proposes that Mike can try to act in #Person1#'s way.\n",
      "\n",
      "Model Generated Output:\n",
      "#Person1#: Mike is acting hurt and sad, but that's not how his character would act in this situation. #Person2#: Jason and Laura have been together for three years. #Person1#: At this point, no. I think he would react the way most guys would, and then later on, we would see his real feelings. #Person2#: I'm not so sure about that.\n",
      "\n",
      "Dialogue:\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "Ground-Truth:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "\n",
      "Model Generated Output:\n",
      "#Person1#: Considering upgrading their system.\n"
     ]
    }
   ],
   "source": [
    "example_indices = [100,200]\n",
    "\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['dialogue']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "    \n",
    "    \n",
    "    prompt = f\"\"\" {dialogue}\\n\\n\n",
    "    \n",
    "    \n",
    "    what each person is doing?\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    output = tokenizer.decode(model.generate(inputs[\"input_ids\"],\n",
    "                  max_new_tokens = 150,\n",
    "                  )[0],\n",
    "                    skip_special_tokens=True\n",
    "                )\n",
    "    print()\n",
    "    print(\"Dialogue:\")\n",
    "    print(dialogue)\n",
    "    \n",
    "    print()\n",
    "    print(\"Ground-Truth:\")\n",
    "    print(summary)\n",
    "    print()\n",
    "    \n",
    "    print(\"Model Generated Output:\")\n",
    "    print(output)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf803b3",
   "metadata": {},
   "source": [
    "# One-shot and few-shot instruction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c59fa244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt:\n",
      "    \n",
      "\n",
      "\n",
      "#Person1#: OK, that's a cut! Let's start from the beginning, everyone.\n",
      "#Person2#: What was the problem that time?\n",
      "#Person1#: The feeling was all wrong, Mike. She is telling you that she doesn't want to see you any more, but I want to get more anger from you. You're acting hurt and sad, but that's not how your character would act in this situation.\n",
      "#Person2#: But Jason and Laura have been together for three years. Don't you think his reaction would be one of both anger and sadness?\n",
      "#Person1#: At this point, no. I think he would react the way most guys would, and then later on, we would see his real feelings.\n",
      "#Person2#: I'm not so sure about that.\n",
      "#Person1#: Let's try it my way, and you can see how you feel when you're saying your lines. After that, if it still doesn't feel right, we can try something else.\n",
      "\n",
      "what each person is doing?\n",
      "\n",
      "    #Person1# and Mike have a disagreement on how to act out a scene. #Person1# proposes that Mike can try to act in #Person1#'s way.\n",
      "    \n",
      "\n",
      "\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "what each person is doing?\n",
      "\n",
      "    #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "    \n",
      "\n",
      "\n",
      "#Person1#: I cannot imagine if Trump were to be our President again.\n",
      "#Person2#: I am proud to say that he is our President, and I will be really happy if he could be re-elected.\n",
      "#Person1#: You voted for him, right?\n",
      "#Person2#: Did you vote for him, because I know that I did.\n",
      "#Person1#: I am not sure about this.\n",
      "#Person2#: I have nothing but faith in Trump.\n",
      "#Person1#: What?\n",
      "#Person2#: I am pretty sure he will make America great again!\n",
      "#Person1#: Well, though we do need some change in this country, I don't think he is the right person.\n",
      "#Person2#: Our country is already changing as it is.\n",
      "#Person1#: You are right about this.\n",
      "#Person2#: I trust that he will take good care of our country.\n",
      "#Person1#: Well, I don't think so. I will vote for Biden anyway.\n",
      "\n",
      "what each person is doing?\n",
      "\n",
      "    #Person1# is crazy for Trump and voted for him. #Person2# doesn't agree with #Person1# on Trump and will vote for Biden.\n",
      "    \n",
      "\n",
      "\n",
      "#Person1#: You're finally here! What took so long?\n",
      "#Person2#: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection.\n",
      "#Person1#: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home.\n",
      "#Person2#: I don't think it can be avoided, to be honest.\n",
      "#Person1#: perhaps it would be better if you started taking public transport system to work.\n",
      "#Person2#: I think it's something that I'll have to consider. The public transport system is pretty good.\n",
      "#Person1#: It would be better for the environment, too.\n",
      "#Person2#: I know. I feel bad about how much my car is adding to the pollution problem in this city.\n",
      "#Person1#: Taking the subway would be a lot less stressful than driving as well.\n",
      "#Person2#: The only problem is that I'm going to really miss having the freedom that you have with a car.\n",
      "#Person1#: Well, when it's nicer outside, you can start biking to work. That will give you just as much freedom as your car usually provides.\n",
      "#Person2#: That's true. I could certainly use the exercise!\n",
      "#Person1#: So, are you going to quit driving to work then?\n",
      "#Person2#: Yes, it's not good for me or for the environment.\n",
      "\n",
      " what each person is doing?\n",
      "\n",
      "Ground-Truth:\n",
      "#Person2# arrives late because of traffic jam. #Person1# persuades #Person2# to use public transportations to keep healthy and to protect the environment.\n",
      "\n",
      "Model Generated Output:\n",
      "#Person1: Getting stuck in traffic. #Person2: Taking public transport to work. #Person1: Taking the subway. #Person2: Biking to work.\n"
     ]
    }
   ],
   "source": [
    "shot = 3\n",
    "\n",
    "example_indices = [100,200,300,400]\n",
    "\n",
    "prompt = \"\"\n",
    "for i, index in enumerate(example_indices[0:shot]):\n",
    "    dialogue = dataset['test'][index]['dialogue']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "    \n",
    "    \n",
    "    prompt = f\"\"\" {prompt}\\n\\n\\n{dialogue}\\n\\nwhat each person is doing?\\n\n",
    "    {summary}\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "dialogue = dataset['test'][shot]['dialogue']\n",
    "summary = dataset['test'][shot]['summary']\n",
    "    \n",
    "prompt = f\"\"\" {prompt}\\n\\n\\n{dialogue}\\n\\n what each person is doing?\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(model.generate(inputs[\"input_ids\"],\n",
    "              max_new_tokens = 50,\n",
    "              )[0],\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "print()\n",
    "print(\"Prompt:\")\n",
    "print(prompt)\n",
    "\n",
    "print()\n",
    "print(\"Ground-Truth:\")\n",
    "print(summary)\n",
    "print()\n",
    "\n",
    "print(\"Model Generated Output:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b5d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
